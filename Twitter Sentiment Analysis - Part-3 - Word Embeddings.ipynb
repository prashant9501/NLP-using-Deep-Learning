{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee738e22",
   "metadata": {},
   "source": [
    "## Load the Tweets Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "951e6f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f789056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>cleaned_tweets</th>\n",
       "      <th>cleaned_tweets_without_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>#fingerprint #Pregnancy Test https://goo.gl/h1MfQV #android #apps #beautiful #cute #health #igers #iphoneonly #iphonesia #iphone</td>\n",
       "      <td>fingerprint pregnancy test android apps beautiful cute health igers iphoneonly iphonesia iphone</td>\n",
       "      <td>fingerprint pregnancy test android apps beautiful cute health igers iphoneonly iphonesia iphone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Finally a transparant silicon case ^^ Thanks to my uncle :) #yay #Sony #Xperia #S #sonyexperias… http://instagram.com/p/YGEt5JC6JM/</td>\n",
       "      <td>finally transparant silicon case thanks uncle yay sony xperia sonyexperias</td>\n",
       "      <td>finally transparant silicon case thanks uncle yay sony xperia sonyexperias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>We love this! Would you go? #talk #makememories #unplug #relax #iphone #smartphone #wifi #connect... http://fb.me/6N3LsUpCu</td>\n",
       "      <td>love this would you talk makememories unplug relax iphone smartphone wifi connect</td>\n",
       "      <td>love talk makememories unplug relax iphone smartphone wifi connect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>I'm wired I know I'm George I was made that way ;) #iphone #cute #daventry #home http://instagr.am/p/Li_5_ujS4k/</td>\n",
       "      <td>wired know george wa made that way iphone cute daventry home</td>\n",
       "      <td>wired know george way iphone cute daventry home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>What amazing service! Apple won't even talk to me about a question I have unless I pay them $19.95 for their stupid support!</td>\n",
       "      <td>what amazing service apple will not even talk about question have unless pay them for their stupid support</td>\n",
       "      <td>amazing service apple talk question unless pay stupid support</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  \\\n",
       "0      1   \n",
       "1      1   \n",
       "2      1   \n",
       "3      1   \n",
       "4      0   \n",
       "\n",
       "                                                                                                                                 tweet  \\\n",
       "0     #fingerprint #Pregnancy Test https://goo.gl/h1MfQV #android #apps #beautiful #cute #health #igers #iphoneonly #iphonesia #iphone   \n",
       "1  Finally a transparant silicon case ^^ Thanks to my uncle :) #yay #Sony #Xperia #S #sonyexperias… http://instagram.com/p/YGEt5JC6JM/   \n",
       "2          We love this! Would you go? #talk #makememories #unplug #relax #iphone #smartphone #wifi #connect... http://fb.me/6N3LsUpCu   \n",
       "3                     I'm wired I know I'm George I was made that way ;) #iphone #cute #daventry #home http://instagr.am/p/Li_5_ujS4k/   \n",
       "4         What amazing service! Apple won't even talk to me about a question I have unless I pay them $19.95 for their stupid support!   \n",
       "\n",
       "                                                                                               cleaned_tweets  \\\n",
       "0             fingerprint pregnancy test android apps beautiful cute health igers iphoneonly iphonesia iphone   \n",
       "1                                  finally transparant silicon case thanks uncle yay sony xperia sonyexperias   \n",
       "2                           love this would you talk makememories unplug relax iphone smartphone wifi connect   \n",
       "3                                                wired know george wa made that way iphone cute daventry home   \n",
       "4  what amazing service apple will not even talk about question have unless pay them for their stupid support   \n",
       "\n",
       "                                                                  cleaned_tweets_without_stopwords  \n",
       "0  fingerprint pregnancy test android apps beautiful cute health igers iphoneonly iphonesia iphone  \n",
       "1                       finally transparant silicon case thanks uncle yay sony xperia sonyexperias  \n",
       "2                               love talk makememories unplug relax iphone smartphone wifi connect  \n",
       "3                                                  wired know george way iphone cute daventry home  \n",
       "4                                    amazing service apple talk question unless pay stupid support  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_pickle(\"cleaned_tweets_v1.pkl\")\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fa23600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7920, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55663f2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5994bc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tweets['cleaned_tweets']\n",
    "y = tweets['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab50e20a",
   "metadata": {},
   "source": [
    "# Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff882921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fingerprint pregnancy test android apps beautiful cute health igers iphoneonly iphonesia iphone'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets['cleaned_tweets'][0]  # 1st tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6b5d491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fingerprint',\n",
       " 'pregnancy',\n",
       " 'test',\n",
       " 'android',\n",
       " 'apps',\n",
       " 'beautiful',\n",
       " 'cute',\n",
       " 'health',\n",
       " 'igers',\n",
       " 'iphoneonly',\n",
       " 'iphonesia',\n",
       " 'iphone']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_list = list(tweets['cleaned_tweets'].apply(lambda x: x.split()))\n",
    "tweets_list[0] # list of lists, where each tweet is a list of tokens, finally we have a list of tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e54e86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c41021b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating our own Word2Vec Model\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# train model\n",
    "cbow_model = Word2Vec(tweets_list, vector_size = 300, window = 3, min_count=10, sg=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c35fccbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec<vocab=1237, vector_size=300, alpha=0.025>\n"
     ]
    }
   ],
   "source": [
    "# summarize the loaded model\n",
    "print(cbow_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b91e2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['iphone', 'apple', 'the', 'samsung', 'and', 'you', 'new', 'twitter', 'for', 'com', 'phone', 'sony', 'not', 'follow', 'this', 'pic', 'with', 'have', 'like', 'ipad']\n"
     ]
    }
   ],
   "source": [
    "print(cbow_model.wv.index_to_key[:20] )   # printing the 1st 20 vocab words!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48e911e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1237"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cbow_model.wv.index_to_key)  # total number of words in the Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d4d49e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.02080035e-02,  1.40748844e-01,  3.83791447e-01,  1.46812379e-01,\n",
       "        1.39446929e-01, -2.13295743e-01,  2.98809707e-01,  5.30503154e-01,\n",
       "        6.64356351e-02,  8.08329880e-03, -1.05925212e-02, -2.45266661e-01,\n",
       "       -2.03678295e-01, -1.52947858e-01, -1.40868686e-02, -2.69171149e-01,\n",
       "        1.34432241e-01,  1.98538508e-02, -2.02673916e-02, -1.78270295e-01,\n",
       "       -2.68751413e-01, -2.41427228e-01,  1.13485806e-01,  8.46207421e-03,\n",
       "        1.20829768e-01, -2.74891347e-01, -2.08213683e-02,  2.32238322e-01,\n",
       "       -1.41006663e-01,  1.00656059e-02,  2.56013535e-02, -1.78655926e-02,\n",
       "       -1.63230654e-02,  3.57875675e-02, -3.00654918e-02,  1.18028782e-01,\n",
       "        4.35441405e-01, -4.54382718e-01, -5.61433993e-02, -5.43568805e-02,\n",
       "       -3.20539926e-04, -2.46322285e-02,  4.69611548e-02, -1.39195547e-01,\n",
       "        2.27178648e-01,  1.28573880e-01,  1.32822886e-01, -5.45659922e-02,\n",
       "        1.79582715e-01,  5.02636671e-01,  1.30560517e-01,  8.25996250e-02,\n",
       "       -1.11747146e-01, -4.75448044e-03,  3.09136277e-03,  4.98242736e-01,\n",
       "       -6.78099543e-02, -5.37143946e-02,  1.93480611e-01, -1.89588368e-01,\n",
       "       -2.61811823e-01,  6.78822249e-02, -8.12907219e-02, -1.43700726e-02,\n",
       "        9.89899263e-02, -5.04966825e-02,  1.75512806e-01,  2.19184831e-01,\n",
       "       -1.83390841e-01, -2.09372103e-01,  1.64439343e-02,  2.32091859e-01,\n",
       "        2.62915641e-01, -3.87805402e-01,  6.50419742e-02, -3.30362767e-02,\n",
       "        4.32152413e-02, -6.37445822e-02,  5.27337380e-02,  3.71518344e-01,\n",
       "        2.52905972e-02, -1.47810847e-01, -3.97346243e-02,  4.71280158e-01,\n",
       "        6.33647814e-02,  2.15311587e-01, -2.89830595e-01, -1.11015469e-01,\n",
       "        2.52994210e-01,  1.50095180e-01,  2.42636889e-01, -2.14244366e-01,\n",
       "       -4.34709340e-03, -1.80736318e-01,  3.50823611e-01,  3.80286753e-01,\n",
       "        3.78723681e-01, -2.30132535e-01, -1.54154465e-01,  9.12481695e-02,\n",
       "        1.06865473e-01,  4.22303304e-02,  4.18944582e-02,  2.98209041e-01,\n",
       "        2.40874663e-01, -3.03562684e-03,  8.61938205e-03,  1.01147778e-01,\n",
       "       -3.12287301e-01, -1.63636461e-01, -3.87698889e-01, -3.27452719e-01,\n",
       "       -1.10368706e-01,  3.36880445e-01, -3.91407646e-02,  8.84370506e-02,\n",
       "        9.85345244e-03,  3.90239172e-02,  8.10979691e-05, -3.00001055e-01,\n",
       "       -2.46981636e-01, -2.91537400e-02,  2.41733953e-01, -1.25773638e-01,\n",
       "       -1.20491974e-01,  3.76501903e-02,  1.04654536e-01, -2.76267290e-01,\n",
       "        1.29416939e-02,  1.00647733e-02, -6.75783679e-02,  2.43225634e-01,\n",
       "        1.41883246e-03, -1.12114772e-01,  2.27384388e-01,  9.64905098e-02,\n",
       "        1.15817547e-01, -6.15815781e-02, -1.60777330e-01, -2.07017988e-01,\n",
       "        6.28864095e-02, -2.99564481e-01, -2.25751586e-02,  1.05931573e-02,\n",
       "        1.72009632e-01,  2.55591851e-02, -3.06072205e-01, -9.80319977e-02,\n",
       "        1.94162413e-01, -1.27357598e-02, -6.61873668e-02, -3.69183332e-01,\n",
       "       -1.36016682e-01,  1.76287107e-02, -1.97794419e-02,  1.34409517e-01,\n",
       "       -2.36893222e-01, -1.18507259e-01, -1.26635686e-01,  1.93732947e-01,\n",
       "        2.71958321e-01,  1.45708621e-01, -3.77050251e-01,  1.13756865e-01,\n",
       "       -3.44626009e-01, -1.52063072e-01,  1.09619051e-01, -2.55725998e-02,\n",
       "        2.28567809e-01,  2.97310978e-01, -1.86711863e-01,  1.27536093e-03,\n",
       "        2.30724700e-02,  2.45827258e-01,  2.44915590e-01, -1.45437598e-01,\n",
       "        5.95970266e-02, -2.29293630e-02, -7.60305226e-02, -1.64299488e-01,\n",
       "       -8.51039141e-02,  6.22168593e-02, -8.99759829e-02, -1.87033087e-01,\n",
       "       -9.23584327e-02,  7.54392818e-02,  4.03631479e-01,  2.82641947e-01,\n",
       "        3.09521761e-02, -2.95205444e-01,  2.40272149e-01, -2.53063980e-02,\n",
       "       -8.57977867e-02,  1.49598554e-01,  4.94134165e-02, -3.41783524e-01,\n",
       "       -1.03850290e-01,  5.16942292e-02,  2.10494101e-01,  7.39466259e-03,\n",
       "       -3.19244385e-01, -5.01581132e-02, -7.94448331e-02, -1.46783128e-01,\n",
       "        6.13090098e-02,  3.77242230e-02, -1.30757406e-01,  1.59523353e-01,\n",
       "       -2.45220393e-01, -1.00154251e-01, -2.20836028e-01, -1.49839401e-01,\n",
       "       -1.87654957e-01, -1.58377767e-01, -9.44123939e-02, -2.53618360e-01,\n",
       "       -2.33831361e-01, -4.14249837e-01, -2.07249731e-01, -2.27257788e-01,\n",
       "        9.35127512e-02, -2.34483858e-03, -1.22445129e-01,  6.60687089e-02,\n",
       "       -5.95068522e-02, -9.42744166e-02, -2.45621987e-02, -1.60302922e-01,\n",
       "       -2.74793804e-01,  1.04054727e-01,  7.59510398e-02, -7.80073628e-02,\n",
       "       -6.35948703e-02, -6.00796752e-02, -1.69657469e-01,  5.79985380e-02,\n",
       "       -1.49296671e-01,  5.65805845e-02,  1.20316751e-01, -3.47561359e-01,\n",
       "        8.80386457e-02, -1.33137360e-01,  1.60464589e-02,  1.25790820e-01,\n",
       "       -4.08495292e-02,  1.17935248e-01, -8.94020963e-03,  2.93447226e-02,\n",
       "       -1.05928533e-01,  4.74842906e-01,  4.21578698e-02, -2.80640900e-01,\n",
       "       -1.09183997e-01, -1.70106083e-01, -2.65799314e-01, -2.12847754e-01,\n",
       "        1.63836628e-01,  1.87351942e-01, -3.50843996e-01, -4.16907072e-02,\n",
       "        2.35765964e-01, -7.10428087e-03,  2.05890372e-01, -4.24494356e-01,\n",
       "       -2.99668670e-01, -1.77307442e-01,  4.48948652e-01,  9.91597697e-02,\n",
       "       -1.71658993e-01, -7.23762512e-02, -7.50107914e-02,  1.09925695e-01,\n",
       "        8.13229159e-02,  2.76082829e-02,  7.67171159e-02,  8.54596496e-02,\n",
       "        1.65675908e-01,  1.75634444e-01, -8.63844007e-02,  6.43870905e-02,\n",
       "        1.17065720e-01, -1.10186726e-01, -6.95377961e-02,  1.88939586e-01,\n",
       "        1.44403819e-02,  1.69003487e-01, -9.97383222e-02,  1.15112700e-01,\n",
       "        1.87494159e-01,  1.06334649e-01, -1.97647735e-01,  2.12161019e-01,\n",
       "        1.93097681e-01,  1.30027786e-01,  3.16966891e-01,  3.20903897e-01,\n",
       "       -1.11684553e-01, -1.67850822e-01,  2.41755500e-01, -1.64370134e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# access word vector for one word\n",
    "cbow_model.wv.get_vector('ipad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a13ee061",
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_vector(doc):\n",
    "    \"\"\"Create document vectors by averaging word vectors. Remove out-of-vocabulary words.\"\"\"\n",
    "    \n",
    "    # doc1 contains those words of the document which are included in the vocab\n",
    "    doc1 = [word for word in doc.split() if word in cbow_model.wv.index_to_key]\n",
    "    \n",
    "    wv1 = []  # this will contain the WE of all the vocab words from the doc\n",
    "    for word in doc1:\n",
    "        wv1.append(cbow_model.wv.get_vector(word))\n",
    "    wv1_ = np.array(wv1)\n",
    "    wv1_mean = wv1_.mean(axis=0)\n",
    "    return wv1_mean\n",
    "\n",
    "# np.mean(model[doc], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f2155294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7920,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "57d97b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_temp = X.apply(document_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "860f2986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7920,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_temp.shape   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "636fbdb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [0.026826207, 0.16647096, 0.14817807, 0.06845369, 0.12645465, -0.20806031, 0.19661863, 0.43319473, 0.089440934, 0.111117825, 0.006400846, -0.11084225, -0.079257414, -0.10315515, -0.15831566, -0.23...\n",
       "1    [0.026638785, 0.19544089, 0.06592562, 0.19374664, 0.074396804, -0.23043604, 0.11404914, 0.33971593, 0.055556074, -0.020716509, -0.024682024, -0.047152627, -0.03719196, -0.07130316, -0.08024793, -0...\n",
       "2    [-0.027298588, 0.17520703, -0.055500813, 0.098311655, 0.031758986, -0.19882078, 0.10240402, 0.32828465, 0.037724294, -0.07731754, -0.035604108, -0.12081506, -0.082958855, -0.05177357, -0.06717392,...\n",
       "3    [-0.014918212, 0.19131161, -0.011942185, 0.1214936, 0.057457495, -0.2309837, 0.13210379, 0.3831135, 0.04729805, -0.05329325, -0.03377345, -0.11867264, -0.081632465, -0.067539744, -0.080679215, -0....\n",
       "4    [-0.037641782, 0.18621095, -0.06971123, 0.1496355, 0.035168614, -0.21614198, 0.09731512, 0.3332366, 0.02101336, -0.13267139, -0.0468873, -0.11370128, -0.08639497, -0.053567152, -0.029889265, -0.08...\n",
       "Name: cleaned_tweets, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_temp[:5]  # displaying the 1st 5 tweets, as document vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3431aee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_temp[0].shape  # each document vector is 300-dimensional !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "37c6a974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tweets_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36849af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7920, 300)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combining all the document vectors into a singl numpy array (tweets_vec)\n",
    "embedding_size = 300\n",
    "tweets_vec = np.ones((len(tweets_temp), embedding_size))*np.nan\n",
    "for i in range(tweets_vec.shape[0]):\n",
    "    tweets_vec[i,:] = tweets_temp.iloc[i]\n",
    "\n",
    "tweets_vec.shape # this itself is your final FEATURE MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f5dc9a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DF to store these new documnent features\n",
    "df = pd.DataFrame(tweets_vec)\n",
    "df['y'] = tweets['label']\n",
    "df.dropna(how='any', axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7ca6c095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.026826</td>\n",
       "      <td>0.166471</td>\n",
       "      <td>0.148178</td>\n",
       "      <td>0.068454</td>\n",
       "      <td>0.126455</td>\n",
       "      <td>-0.208060</td>\n",
       "      <td>0.196619</td>\n",
       "      <td>0.433195</td>\n",
       "      <td>0.089441</td>\n",
       "      <td>0.111118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.308817</td>\n",
       "      <td>0.122169</td>\n",
       "      <td>0.002031</td>\n",
       "      <td>0.192916</td>\n",
       "      <td>0.364714</td>\n",
       "      <td>0.032367</td>\n",
       "      <td>-0.056186</td>\n",
       "      <td>0.169601</td>\n",
       "      <td>-0.110197</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.026639</td>\n",
       "      <td>0.195441</td>\n",
       "      <td>0.065926</td>\n",
       "      <td>0.193747</td>\n",
       "      <td>0.074397</td>\n",
       "      <td>-0.230436</td>\n",
       "      <td>0.114049</td>\n",
       "      <td>0.339716</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>-0.020717</td>\n",
       "      <td>...</td>\n",
       "      <td>0.233975</td>\n",
       "      <td>0.103947</td>\n",
       "      <td>0.048142</td>\n",
       "      <td>0.208316</td>\n",
       "      <td>0.201495</td>\n",
       "      <td>0.016743</td>\n",
       "      <td>-0.063562</td>\n",
       "      <td>0.167798</td>\n",
       "      <td>-0.096593</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.027299</td>\n",
       "      <td>0.175207</td>\n",
       "      <td>-0.055501</td>\n",
       "      <td>0.098312</td>\n",
       "      <td>0.031759</td>\n",
       "      <td>-0.198821</td>\n",
       "      <td>0.102404</td>\n",
       "      <td>0.328285</td>\n",
       "      <td>0.037724</td>\n",
       "      <td>-0.077318</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232205</td>\n",
       "      <td>0.130381</td>\n",
       "      <td>-0.005101</td>\n",
       "      <td>0.172866</td>\n",
       "      <td>0.158324</td>\n",
       "      <td>-0.039869</td>\n",
       "      <td>-0.082533</td>\n",
       "      <td>0.130919</td>\n",
       "      <td>-0.099018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.014918</td>\n",
       "      <td>0.191312</td>\n",
       "      <td>-0.011942</td>\n",
       "      <td>0.121494</td>\n",
       "      <td>0.057457</td>\n",
       "      <td>-0.230984</td>\n",
       "      <td>0.132104</td>\n",
       "      <td>0.383114</td>\n",
       "      <td>0.047298</td>\n",
       "      <td>-0.053293</td>\n",
       "      <td>...</td>\n",
       "      <td>0.269170</td>\n",
       "      <td>0.137099</td>\n",
       "      <td>0.000961</td>\n",
       "      <td>0.201074</td>\n",
       "      <td>0.215511</td>\n",
       "      <td>-0.033859</td>\n",
       "      <td>-0.082470</td>\n",
       "      <td>0.155982</td>\n",
       "      <td>-0.108283</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.037642</td>\n",
       "      <td>0.186211</td>\n",
       "      <td>-0.069711</td>\n",
       "      <td>0.149635</td>\n",
       "      <td>0.035169</td>\n",
       "      <td>-0.216142</td>\n",
       "      <td>0.097315</td>\n",
       "      <td>0.333237</td>\n",
       "      <td>0.021013</td>\n",
       "      <td>-0.132671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.217421</td>\n",
       "      <td>0.125933</td>\n",
       "      <td>0.008542</td>\n",
       "      <td>0.192938</td>\n",
       "      <td>0.113935</td>\n",
       "      <td>-0.071039</td>\n",
       "      <td>-0.099378</td>\n",
       "      <td>0.142263</td>\n",
       "      <td>-0.093069</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.026826  0.166471  0.148178  0.068454  0.126455 -0.208060  0.196619   \n",
       "1  0.026639  0.195441  0.065926  0.193747  0.074397 -0.230436  0.114049   \n",
       "2 -0.027299  0.175207 -0.055501  0.098312  0.031759 -0.198821  0.102404   \n",
       "3 -0.014918  0.191312 -0.011942  0.121494  0.057457 -0.230984  0.132104   \n",
       "4 -0.037642  0.186211 -0.069711  0.149635  0.035169 -0.216142  0.097315   \n",
       "\n",
       "          7         8         9  ...       291       292       293       294  \\\n",
       "0  0.433195  0.089441  0.111118  ...  0.308817  0.122169  0.002031  0.192916   \n",
       "1  0.339716  0.055556 -0.020717  ...  0.233975  0.103947  0.048142  0.208316   \n",
       "2  0.328285  0.037724 -0.077318  ...  0.232205  0.130381 -0.005101  0.172866   \n",
       "3  0.383114  0.047298 -0.053293  ...  0.269170  0.137099  0.000961  0.201074   \n",
       "4  0.333237  0.021013 -0.132671  ...  0.217421  0.125933  0.008542  0.192938   \n",
       "\n",
       "        295       296       297       298       299  y  \n",
       "0  0.364714  0.032367 -0.056186  0.169601 -0.110197  1  \n",
       "1  0.201495  0.016743 -0.063562  0.167798 -0.096593  1  \n",
       "2  0.158324 -0.039869 -0.082533  0.130919 -0.099018  1  \n",
       "3  0.215511 -0.033859 -0.082470  0.155982 -0.108283  1  \n",
       "4  0.113935 -0.071039 -0.099378  0.142263 -0.093069  0  \n",
       "\n",
       "[5 rows x 301 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "98183b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7920, 301)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5efba4fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7920, 300)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_word_emb = df.drop('y', axis=1)\n",
    "y = df['y']\n",
    "X_word_emb.shape   # final feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "91ef3a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "n_splits = 5\n",
    "kfold = StratifiedKFold(n_splits, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "59fa52a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8336 0.0025\n",
      "0.8326 0.0059\n"
     ]
    }
   ],
   "source": [
    "LR = LogisticRegression(solver='liblinear', class_weight='balanced', penalty='l2', C=0.5)\n",
    "\n",
    "results = cross_validate(LR, X_word_emb, y, scoring='accuracy', cv=kfold, \\\n",
    "                         return_train_score=True, return_estimator=True)\n",
    "print(results['train_score'].mean().round(4), results['train_score'].std().round(4))\n",
    "print(results['test_score'].mean().round(4), results['test_score'].std().round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdd64cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# H/W Try putting the Word Embedding part also in a pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e44aac",
   "metadata": {},
   "source": [
    "# Word Embeddings from GloVe Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b72f3cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "66a2d156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the converted model\n",
    "filename = 'word2vec.txt'\n",
    "model = KeyedVectors.load_word2vec_format(filename, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "938b3351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.1104e-01, -4.7861e-01,  4.6234e-01, -5.8098e-02,  3.5714e-01,\n",
       "       -7.4596e-02,  6.9281e-01, -3.9926e-01,  7.5479e-01,  4.4398e-01,\n",
       "        3.4338e-01, -4.3246e-01,  7.0191e-02, -8.6011e-01,  2.3844e-01,\n",
       "       -2.8153e-02, -5.6473e-01,  1.1724e+00,  6.9807e-01,  5.8976e-01,\n",
       "        1.2442e-01, -1.2911e+00,  8.9142e-01,  1.0527e+00,  9.8682e-01,\n",
       "        9.2627e-01,  2.9873e-01,  3.0862e-01, -7.4524e-01,  1.2628e-01,\n",
       "       -2.3706e-01,  1.6102e+00,  4.7798e-03,  1.9434e-01,  1.0604e+00,\n",
       "        7.8258e-01, -8.9174e-01,  1.6738e-01,  4.7110e-01, -7.6120e-01,\n",
       "        3.0506e-01, -1.8910e-01,  6.6989e-02, -5.2704e-01, -4.1588e-01,\n",
       "        2.2908e-01,  5.0584e-01, -4.6857e-01,  7.7799e-01,  6.3018e-01,\n",
       "        3.6416e-01,  2.5758e-01,  3.0741e-01, -1.3649e-01, -7.5056e-01,\n",
       "       -4.1256e-01, -3.2920e-01, -4.9191e-01,  4.0316e-01, -5.6319e-01,\n",
       "        1.5338e-01,  6.2828e-01, -4.3093e-01,  4.9648e-01, -3.8445e-01,\n",
       "        8.8047e-02,  8.1446e-02, -7.0781e-01,  2.2075e-01, -7.0370e-01,\n",
       "        1.2314e+00,  8.8133e-01, -2.5433e-01, -8.6200e-01, -7.8156e-01,\n",
       "        1.2148e+00,  1.5692e-01,  3.2605e-01, -9.0904e-02, -4.6774e-01,\n",
       "        1.9912e-01, -1.0419e+00,  1.3624e-01,  5.2345e-01, -8.3541e-01,\n",
       "       -4.5644e-01,  6.3295e-01, -6.1910e-02, -1.0423e-01, -1.8349e-04,\n",
       "        3.3583e-01,  1.3266e+00,  3.0262e-01, -4.9175e-01, -1.1317e-01,\n",
       "       -1.7594e-01,  9.0333e-02,  1.4733e-01,  1.0758e+00,  3.5354e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_vector('ipad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "79c43ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " ',',\n",
       " '.',\n",
       " 'of',\n",
       " 'to',\n",
       " 'and',\n",
       " 'in',\n",
       " 'a',\n",
       " '\"',\n",
       " \"'s\",\n",
       " 'for',\n",
       " '-',\n",
       " 'that',\n",
       " 'on',\n",
       " 'is',\n",
       " 'was',\n",
       " 'said',\n",
       " 'with',\n",
       " 'he',\n",
       " 'as',\n",
       " 'it',\n",
       " 'by',\n",
       " 'at',\n",
       " '(',\n",
       " ')',\n",
       " 'from',\n",
       " 'his',\n",
       " \"''\",\n",
       " '``',\n",
       " 'an',\n",
       " 'be',\n",
       " 'has',\n",
       " 'are',\n",
       " 'have',\n",
       " 'but',\n",
       " 'were',\n",
       " 'not',\n",
       " 'this',\n",
       " 'who',\n",
       " 'they',\n",
       " 'had',\n",
       " 'i',\n",
       " 'which',\n",
       " 'will',\n",
       " 'their',\n",
       " ':',\n",
       " 'or',\n",
       " 'its',\n",
       " 'one',\n",
       " 'after',\n",
       " 'new',\n",
       " 'been',\n",
       " 'also',\n",
       " 'we',\n",
       " 'would',\n",
       " 'two',\n",
       " 'more',\n",
       " \"'\",\n",
       " 'first',\n",
       " 'about',\n",
       " 'up',\n",
       " 'when',\n",
       " 'year',\n",
       " 'there',\n",
       " 'all',\n",
       " '--',\n",
       " 'out',\n",
       " 'she',\n",
       " 'other',\n",
       " 'people',\n",
       " \"n't\",\n",
       " 'her',\n",
       " 'percent',\n",
       " 'than',\n",
       " 'over',\n",
       " 'into',\n",
       " 'last',\n",
       " 'some',\n",
       " 'government',\n",
       " 'time',\n",
       " '$',\n",
       " 'you',\n",
       " 'years',\n",
       " 'if',\n",
       " 'no',\n",
       " 'world',\n",
       " 'can',\n",
       " 'three',\n",
       " 'do',\n",
       " ';',\n",
       " 'president',\n",
       " 'only',\n",
       " 'state',\n",
       " 'million',\n",
       " 'could',\n",
       " 'us',\n",
       " 'most',\n",
       " '_',\n",
       " 'against',\n",
       " 'u.s.',\n",
       " 'so',\n",
       " 'them',\n",
       " 'what',\n",
       " 'him',\n",
       " 'united',\n",
       " 'during',\n",
       " 'before',\n",
       " 'may',\n",
       " 'since',\n",
       " 'many',\n",
       " 'while',\n",
       " 'where',\n",
       " 'states',\n",
       " 'because',\n",
       " 'now',\n",
       " 'city',\n",
       " 'made',\n",
       " 'like',\n",
       " 'between',\n",
       " 'did',\n",
       " 'just',\n",
       " 'national',\n",
       " 'day',\n",
       " 'country',\n",
       " 'under',\n",
       " 'such',\n",
       " 'second',\n",
       " 'then',\n",
       " 'company',\n",
       " 'group',\n",
       " 'any',\n",
       " 'through',\n",
       " 'china',\n",
       " 'four',\n",
       " 'being',\n",
       " 'down',\n",
       " 'war',\n",
       " 'back',\n",
       " 'off',\n",
       " 'south',\n",
       " 'american',\n",
       " 'minister',\n",
       " 'police',\n",
       " 'well',\n",
       " 'including',\n",
       " 'team',\n",
       " 'international',\n",
       " 'week',\n",
       " 'officials',\n",
       " 'still',\n",
       " 'both',\n",
       " 'even',\n",
       " 'high',\n",
       " 'part',\n",
       " 'told',\n",
       " 'those',\n",
       " 'end',\n",
       " 'former',\n",
       " 'these',\n",
       " 'make',\n",
       " 'billion',\n",
       " 'work',\n",
       " 'our',\n",
       " 'home',\n",
       " 'school',\n",
       " 'party',\n",
       " 'house',\n",
       " 'old',\n",
       " 'later',\n",
       " 'get',\n",
       " 'another',\n",
       " 'tuesday',\n",
       " 'news',\n",
       " 'long',\n",
       " 'five',\n",
       " 'called',\n",
       " '1',\n",
       " 'wednesday',\n",
       " 'military',\n",
       " 'way',\n",
       " 'used',\n",
       " 'much',\n",
       " 'next',\n",
       " 'monday',\n",
       " 'thursday',\n",
       " 'friday',\n",
       " 'game',\n",
       " 'here',\n",
       " '?',\n",
       " 'should',\n",
       " 'take',\n",
       " 'very',\n",
       " 'my',\n",
       " 'north',\n",
       " 'security',\n",
       " 'season',\n",
       " 'york',\n",
       " 'how',\n",
       " 'public',\n",
       " 'early',\n",
       " 'according',\n",
       " 'several',\n",
       " 'court',\n",
       " 'say',\n",
       " 'around',\n",
       " 'foreign',\n",
       " '10',\n",
       " 'until',\n",
       " 'set',\n",
       " 'political',\n",
       " 'says',\n",
       " 'market',\n",
       " 'however',\n",
       " 'family',\n",
       " 'life',\n",
       " 'same',\n",
       " 'general',\n",
       " '–',\n",
       " 'left',\n",
       " 'good',\n",
       " 'top',\n",
       " 'university',\n",
       " 'going',\n",
       " 'number',\n",
       " 'major',\n",
       " 'known',\n",
       " 'points',\n",
       " 'won',\n",
       " 'six',\n",
       " 'month',\n",
       " 'dollars',\n",
       " 'bank',\n",
       " '2',\n",
       " 'iraq',\n",
       " 'use',\n",
       " 'members',\n",
       " 'each',\n",
       " 'area',\n",
       " 'found',\n",
       " 'official',\n",
       " 'sunday',\n",
       " 'place',\n",
       " 'go',\n",
       " 'based',\n",
       " 'among',\n",
       " 'third',\n",
       " 'times',\n",
       " 'took',\n",
       " 'right',\n",
       " 'days',\n",
       " 'local',\n",
       " 'economic',\n",
       " 'countries',\n",
       " 'see',\n",
       " 'best',\n",
       " 'report',\n",
       " 'killed',\n",
       " 'held',\n",
       " 'business',\n",
       " 'west',\n",
       " 'does',\n",
       " 'own',\n",
       " '%',\n",
       " 'came',\n",
       " 'law',\n",
       " 'months',\n",
       " 'women',\n",
       " \"'re\",\n",
       " 'power',\n",
       " 'think',\n",
       " 'service',\n",
       " 'children',\n",
       " 'bush',\n",
       " 'show',\n",
       " '/',\n",
       " 'help',\n",
       " 'chief',\n",
       " 'saturday',\n",
       " 'system',\n",
       " 'john',\n",
       " 'support',\n",
       " 'series',\n",
       " 'play',\n",
       " 'office',\n",
       " 'following',\n",
       " 'me',\n",
       " 'meeting',\n",
       " 'expected',\n",
       " 'late',\n",
       " 'washington',\n",
       " 'games',\n",
       " 'european',\n",
       " 'league',\n",
       " 'reported',\n",
       " 'final',\n",
       " 'added',\n",
       " 'without',\n",
       " 'british',\n",
       " 'white',\n",
       " 'history',\n",
       " 'man',\n",
       " 'men',\n",
       " 'became',\n",
       " 'want',\n",
       " 'march',\n",
       " 'case',\n",
       " 'few',\n",
       " 'run',\n",
       " 'money',\n",
       " 'began',\n",
       " 'open',\n",
       " 'name',\n",
       " 'trade',\n",
       " 'center',\n",
       " '3',\n",
       " 'israel',\n",
       " 'oil',\n",
       " 'too',\n",
       " 'al',\n",
       " 'film',\n",
       " 'win',\n",
       " 'led',\n",
       " 'east',\n",
       " 'central',\n",
       " '20',\n",
       " 'air',\n",
       " 'come',\n",
       " 'chinese',\n",
       " 'town',\n",
       " 'leader',\n",
       " 'army',\n",
       " 'line',\n",
       " 'never',\n",
       " 'little',\n",
       " 'played',\n",
       " 'prime',\n",
       " 'death',\n",
       " 'companies',\n",
       " 'least',\n",
       " 'put',\n",
       " 'forces',\n",
       " 'past',\n",
       " 'de',\n",
       " 'half',\n",
       " 'june',\n",
       " 'saying',\n",
       " 'know',\n",
       " 'federal',\n",
       " 'french',\n",
       " 'peace',\n",
       " 'earlier',\n",
       " 'capital',\n",
       " 'force',\n",
       " 'great',\n",
       " 'union',\n",
       " 'near',\n",
       " 'released',\n",
       " 'small',\n",
       " 'department',\n",
       " 'every',\n",
       " 'health',\n",
       " 'japan',\n",
       " 'head',\n",
       " 'ago',\n",
       " 'night',\n",
       " 'big',\n",
       " 'cup',\n",
       " 'election',\n",
       " 'region',\n",
       " 'director',\n",
       " 'talks',\n",
       " 'program',\n",
       " 'far',\n",
       " 'today',\n",
       " 'statement',\n",
       " 'july',\n",
       " 'although',\n",
       " 'district',\n",
       " 'again',\n",
       " 'born',\n",
       " 'development',\n",
       " 'leaders',\n",
       " 'council',\n",
       " 'close',\n",
       " 'record',\n",
       " 'along',\n",
       " 'county',\n",
       " 'france',\n",
       " 'went',\n",
       " 'point',\n",
       " 'must',\n",
       " 'spokesman',\n",
       " 'your',\n",
       " 'member',\n",
       " 'plan',\n",
       " 'financial',\n",
       " 'april',\n",
       " 'recent',\n",
       " 'campaign',\n",
       " 'become',\n",
       " 'troops',\n",
       " 'whether',\n",
       " 'lost',\n",
       " 'music',\n",
       " '15',\n",
       " 'got',\n",
       " 'israeli',\n",
       " '30',\n",
       " 'need',\n",
       " '4',\n",
       " 'lead',\n",
       " 'already',\n",
       " 'russia',\n",
       " 'though',\n",
       " 'might',\n",
       " 'free',\n",
       " 'hit',\n",
       " 'rights',\n",
       " '11',\n",
       " 'information',\n",
       " 'away',\n",
       " '12',\n",
       " '5',\n",
       " 'others',\n",
       " 'control',\n",
       " 'within',\n",
       " 'large',\n",
       " 'economy',\n",
       " 'press',\n",
       " 'agency',\n",
       " 'water',\n",
       " 'died',\n",
       " 'career',\n",
       " 'making',\n",
       " '...',\n",
       " 'deal',\n",
       " 'attack',\n",
       " 'side',\n",
       " 'seven',\n",
       " 'better',\n",
       " 'less',\n",
       " 'september',\n",
       " 'once',\n",
       " 'clinton',\n",
       " 'main',\n",
       " 'due',\n",
       " 'committee',\n",
       " 'building',\n",
       " 'conference',\n",
       " 'club',\n",
       " 'january',\n",
       " 'decision',\n",
       " 'stock',\n",
       " 'america',\n",
       " 'given',\n",
       " 'give',\n",
       " 'often',\n",
       " 'announced',\n",
       " 'television',\n",
       " 'industry',\n",
       " 'order',\n",
       " 'young',\n",
       " \"'ve\",\n",
       " 'palestinian',\n",
       " 'age',\n",
       " 'start',\n",
       " 'administration',\n",
       " 'russian',\n",
       " 'prices',\n",
       " 'round',\n",
       " 'december',\n",
       " 'nations',\n",
       " \"'m\",\n",
       " 'human',\n",
       " 'india',\n",
       " 'defense',\n",
       " 'asked',\n",
       " 'total',\n",
       " 'october',\n",
       " 'players',\n",
       " 'bill',\n",
       " 'important',\n",
       " 'southern',\n",
       " 'move',\n",
       " 'fire',\n",
       " 'population',\n",
       " 'rose',\n",
       " 'november',\n",
       " 'include',\n",
       " 'further',\n",
       " 'nuclear',\n",
       " 'street',\n",
       " 'taken',\n",
       " 'media',\n",
       " 'different',\n",
       " 'issue',\n",
       " 'received',\n",
       " 'secretary',\n",
       " 'return',\n",
       " 'college',\n",
       " 'working',\n",
       " 'community',\n",
       " 'eight',\n",
       " 'groups',\n",
       " 'despite',\n",
       " 'level',\n",
       " 'largest',\n",
       " 'whose',\n",
       " 'attacks',\n",
       " 'germany',\n",
       " 'august',\n",
       " 'change',\n",
       " 'church',\n",
       " 'nation',\n",
       " 'german',\n",
       " 'station',\n",
       " 'london',\n",
       " 'weeks',\n",
       " 'having',\n",
       " '18',\n",
       " 'research',\n",
       " 'black',\n",
       " 'services',\n",
       " 'story',\n",
       " '6',\n",
       " 'europe',\n",
       " 'sales',\n",
       " 'policy',\n",
       " 'visit',\n",
       " 'northern',\n",
       " 'lot',\n",
       " 'across',\n",
       " 'per',\n",
       " 'current',\n",
       " 'board',\n",
       " 'football',\n",
       " 'ministry',\n",
       " 'workers',\n",
       " 'vote',\n",
       " 'book',\n",
       " 'fell',\n",
       " 'seen',\n",
       " 'role',\n",
       " 'students',\n",
       " 'shares',\n",
       " 'iran',\n",
       " 'process',\n",
       " 'agreement',\n",
       " 'quarter',\n",
       " 'full',\n",
       " 'match',\n",
       " 'started',\n",
       " 'growth',\n",
       " 'yet',\n",
       " 'moved',\n",
       " 'possible',\n",
       " 'western',\n",
       " 'special',\n",
       " '100',\n",
       " 'plans',\n",
       " 'interest',\n",
       " 'behind',\n",
       " 'strong',\n",
       " 'england',\n",
       " 'named',\n",
       " 'food',\n",
       " 'period',\n",
       " 'real',\n",
       " 'authorities',\n",
       " 'car',\n",
       " 'term',\n",
       " 'rate',\n",
       " 'race',\n",
       " 'nearly',\n",
       " 'korea',\n",
       " 'enough',\n",
       " 'site',\n",
       " 'opposition',\n",
       " 'keep',\n",
       " '25',\n",
       " 'call',\n",
       " 'future',\n",
       " 'taking',\n",
       " 'island',\n",
       " '2008',\n",
       " '2006',\n",
       " 'road',\n",
       " 'outside',\n",
       " 'really',\n",
       " 'century',\n",
       " 'democratic',\n",
       " 'almost',\n",
       " 'single',\n",
       " 'share',\n",
       " 'leading',\n",
       " 'trying',\n",
       " 'find',\n",
       " 'album',\n",
       " 'senior',\n",
       " 'minutes',\n",
       " 'together',\n",
       " 'congress',\n",
       " 'index',\n",
       " 'australia',\n",
       " 'results',\n",
       " 'hard',\n",
       " 'hours',\n",
       " 'land',\n",
       " 'action',\n",
       " 'higher',\n",
       " 'field',\n",
       " 'cut',\n",
       " 'coach',\n",
       " 'elections',\n",
       " 'san',\n",
       " 'issues',\n",
       " 'executive',\n",
       " 'february',\n",
       " 'production',\n",
       " 'areas',\n",
       " 'river',\n",
       " 'face',\n",
       " 'using',\n",
       " 'japanese',\n",
       " 'province',\n",
       " 'park',\n",
       " 'price',\n",
       " 'commission',\n",
       " 'california',\n",
       " 'father',\n",
       " 'son',\n",
       " 'education',\n",
       " '7',\n",
       " 'village',\n",
       " 'energy',\n",
       " 'shot',\n",
       " 'short',\n",
       " 'africa',\n",
       " 'key',\n",
       " 'red',\n",
       " 'association',\n",
       " 'average',\n",
       " 'pay',\n",
       " 'exchange',\n",
       " 'eu',\n",
       " 'something',\n",
       " 'gave',\n",
       " 'likely',\n",
       " 'player',\n",
       " 'george',\n",
       " '2007',\n",
       " 'victory',\n",
       " '8',\n",
       " 'low',\n",
       " 'things',\n",
       " '2010',\n",
       " 'pakistan',\n",
       " '14',\n",
       " 'post',\n",
       " 'social',\n",
       " 'continue',\n",
       " 'ever',\n",
       " 'look',\n",
       " 'chairman',\n",
       " 'job',\n",
       " '2000',\n",
       " 'soldiers',\n",
       " 'able',\n",
       " 'parliament',\n",
       " 'front',\n",
       " 'himself',\n",
       " 'problems',\n",
       " 'private',\n",
       " 'lower',\n",
       " 'list',\n",
       " 'built',\n",
       " '13',\n",
       " 'efforts',\n",
       " 'dollar',\n",
       " 'miles',\n",
       " 'included',\n",
       " 'radio',\n",
       " 'live',\n",
       " 'form',\n",
       " 'david',\n",
       " 'african',\n",
       " 'increase',\n",
       " 'reports',\n",
       " 'sent',\n",
       " 'fourth',\n",
       " 'always',\n",
       " 'king',\n",
       " '50',\n",
       " 'tax',\n",
       " 'taiwan',\n",
       " 'britain',\n",
       " '16',\n",
       " 'playing',\n",
       " 'title',\n",
       " 'middle',\n",
       " 'meet',\n",
       " 'global',\n",
       " 'wife',\n",
       " '2009',\n",
       " 'position',\n",
       " 'located',\n",
       " 'clear',\n",
       " 'ahead',\n",
       " '2004',\n",
       " '2005',\n",
       " 'iraqi',\n",
       " 'english',\n",
       " 'result',\n",
       " 'release',\n",
       " 'violence',\n",
       " 'goal',\n",
       " 'project',\n",
       " 'closed',\n",
       " 'border',\n",
       " 'body',\n",
       " 'soon',\n",
       " 'crisis',\n",
       " 'division',\n",
       " '&amp;',\n",
       " 'served',\n",
       " 'tour',\n",
       " 'hospital',\n",
       " 'kong',\n",
       " 'test',\n",
       " 'hong',\n",
       " 'u.n.',\n",
       " 'inc.',\n",
       " 'technology',\n",
       " 'believe',\n",
       " 'organization',\n",
       " 'published',\n",
       " 'weapons',\n",
       " 'agreed',\n",
       " 'why',\n",
       " 'nine',\n",
       " 'summer',\n",
       " 'wanted',\n",
       " 'republican',\n",
       " 'act',\n",
       " 'recently',\n",
       " 'texas',\n",
       " 'course',\n",
       " 'problem',\n",
       " 'senate',\n",
       " 'medical',\n",
       " 'un',\n",
       " 'done',\n",
       " 'reached',\n",
       " 'star',\n",
       " 'continued',\n",
       " 'investors',\n",
       " 'living',\n",
       " 'care',\n",
       " 'signed',\n",
       " '17',\n",
       " 'art',\n",
       " 'provide',\n",
       " 'worked',\n",
       " 'presidential',\n",
       " 'gold',\n",
       " 'obama',\n",
       " 'morning',\n",
       " 'dead',\n",
       " 'opened',\n",
       " \"'ll\",\n",
       " 'event',\n",
       " 'previous',\n",
       " 'cost',\n",
       " 'instead',\n",
       " 'canada',\n",
       " 'band',\n",
       " 'teams',\n",
       " 'daily',\n",
       " '2001',\n",
       " 'available',\n",
       " 'drug',\n",
       " 'coming',\n",
       " '2003',\n",
       " 'investment',\n",
       " '’s',\n",
       " 'michael',\n",
       " 'civil',\n",
       " 'woman',\n",
       " 'training',\n",
       " 'appeared',\n",
       " '9',\n",
       " 'involved',\n",
       " 'indian',\n",
       " 'similar',\n",
       " 'situation',\n",
       " '24',\n",
       " 'los',\n",
       " 'running',\n",
       " 'fighting',\n",
       " 'mark',\n",
       " '40',\n",
       " 'trial',\n",
       " 'hold',\n",
       " 'australian',\n",
       " 'thought',\n",
       " '!',\n",
       " 'study',\n",
       " 'fall',\n",
       " 'mother',\n",
       " 'met',\n",
       " 'relations',\n",
       " 'anti',\n",
       " '2002',\n",
       " 'song',\n",
       " 'popular',\n",
       " 'base',\n",
       " 'tv',\n",
       " 'ground',\n",
       " 'markets',\n",
       " 'ii',\n",
       " 'newspaper',\n",
       " 'staff',\n",
       " 'saw',\n",
       " 'hand',\n",
       " 'hope',\n",
       " 'operations',\n",
       " 'pressure',\n",
       " 'americans',\n",
       " 'eastern',\n",
       " 'st.',\n",
       " 'legal',\n",
       " 'asia',\n",
       " 'budget',\n",
       " 'returned',\n",
       " 'considered',\n",
       " 'love',\n",
       " 'wrote',\n",
       " 'stop',\n",
       " 'fight',\n",
       " 'currently',\n",
       " 'charges',\n",
       " 'try',\n",
       " 'aid',\n",
       " 'ended',\n",
       " 'management',\n",
       " 'brought',\n",
       " 'cases',\n",
       " 'decided',\n",
       " 'failed',\n",
       " 'network',\n",
       " 'works',\n",
       " 'gas',\n",
       " 'turned',\n",
       " 'fact',\n",
       " 'vice',\n",
       " 'ca',\n",
       " 'mexico',\n",
       " 'trading',\n",
       " 'especially',\n",
       " 'reporters',\n",
       " 'afghanistan',\n",
       " 'common',\n",
       " 'looking',\n",
       " 'space',\n",
       " 'rates',\n",
       " 'manager',\n",
       " 'loss',\n",
       " '2011',\n",
       " 'justice',\n",
       " 'thousands',\n",
       " 'james',\n",
       " 'rather',\n",
       " 'fund',\n",
       " 'thing',\n",
       " 'republic',\n",
       " 'opening',\n",
       " 'accused',\n",
       " 'winning',\n",
       " 'scored',\n",
       " 'championship',\n",
       " 'example',\n",
       " 'getting',\n",
       " 'biggest',\n",
       " 'performance',\n",
       " 'sports',\n",
       " '1998',\n",
       " 'let',\n",
       " 'allowed',\n",
       " 'schools',\n",
       " 'means',\n",
       " 'turn',\n",
       " 'leave',\n",
       " 'no.',\n",
       " 'robert',\n",
       " 'personal',\n",
       " 'stocks',\n",
       " 'showed',\n",
       " 'light',\n",
       " 'arrested',\n",
       " 'person',\n",
       " 'either',\n",
       " 'offer',\n",
       " 'majority',\n",
       " 'battle',\n",
       " '19',\n",
       " 'class',\n",
       " 'evidence',\n",
       " 'makes',\n",
       " 'society',\n",
       " 'products',\n",
       " 'regional',\n",
       " 'needed',\n",
       " 'stage',\n",
       " 'am',\n",
       " 'doing',\n",
       " 'families',\n",
       " 'construction',\n",
       " 'various',\n",
       " '1996',\n",
       " 'sold',\n",
       " 'independent',\n",
       " 'kind',\n",
       " 'airport',\n",
       " 'paul',\n",
       " 'judge',\n",
       " 'internet',\n",
       " 'movement',\n",
       " 'room',\n",
       " 'followed',\n",
       " 'original',\n",
       " 'angeles',\n",
       " 'italy',\n",
       " '`',\n",
       " 'data',\n",
       " 'comes',\n",
       " 'parties',\n",
       " 'nothing',\n",
       " 'sea',\n",
       " 'bring',\n",
       " '2012',\n",
       " 'annual',\n",
       " 'officer',\n",
       " 'beijing',\n",
       " 'present',\n",
       " 'remain',\n",
       " 'nato',\n",
       " '1999',\n",
       " '22',\n",
       " 'remains',\n",
       " 'allow',\n",
       " 'florida',\n",
       " 'computer',\n",
       " '21',\n",
       " 'contract',\n",
       " 'coast',\n",
       " 'created',\n",
       " 'demand',\n",
       " 'operation',\n",
       " 'events',\n",
       " 'islamic',\n",
       " 'beat',\n",
       " 'analysts',\n",
       " 'interview',\n",
       " 'helped',\n",
       " 'child',\n",
       " 'probably',\n",
       " 'spent',\n",
       " 'asian',\n",
       " 'effort',\n",
       " 'cooperation',\n",
       " 'shows',\n",
       " 'calls',\n",
       " 'investigation',\n",
       " 'lives',\n",
       " 'video',\n",
       " 'yen',\n",
       " 'runs',\n",
       " 'tried',\n",
       " 'bad',\n",
       " 'described',\n",
       " '1994',\n",
       " 'toward',\n",
       " 'written',\n",
       " 'throughout',\n",
       " 'established',\n",
       " 'mission',\n",
       " 'associated',\n",
       " 'buy',\n",
       " 'growing',\n",
       " 'green',\n",
       " 'forward',\n",
       " 'competition',\n",
       " 'poor',\n",
       " 'latest',\n",
       " 'banks',\n",
       " 'question',\n",
       " '1997',\n",
       " 'prison',\n",
       " 'feel',\n",
       " 'attention',\n",
       " ...]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.index_to_key  # entire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dbf2a57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_vector_GloVe(doc):\n",
    "    \"\"\"Create document vectors by averaging word vectors. Remove out-of-vocabulary words.\"\"\"\n",
    "    \n",
    "    # doc1 contains those words of the document which are included in the vocab\n",
    "    doc1 = [word for word in doc.split() if word in model.index_to_key]\n",
    "    \n",
    "    wv1 = []  # this will contain the WE of all the vocab words from the doc\n",
    "    for word in doc1:\n",
    "        wv1.append(model.get_vector(word))\n",
    "    wv1_ = np.array(wv1)\n",
    "    wv1_mean = wv1_.mean(axis=0)\n",
    "    return wv1_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "99ed8529",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_temp1 = X.apply(document_vector_GloVe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "31db78ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [-0.12796232, 0.004934112, 0.2997002, -0.1567011, -0.15583865, 0.09799757, 0.11052724, 0.035929985, 0.22409555, 0.35114682, 0.115047574, -0.15497755, 0.023922225, -0.14416587, 0.61092, 0.21855089,...\n",
       "1       [0.18464375, -0.14675263, 0.44942373, 0.09611425, 0.10299387, -0.22091424, 0.09669463, -0.25706288, 0.0071493685, -0.15944123, 0.41342202, -0.015069997, -0.07561076, -0.042483754, -0.011530001, -0...\n",
       "2       [-0.24398555, 0.050635442, 0.40788, -0.21215816, -0.09722363, 0.19359446, -0.23326969, 0.025276013, 0.38502225, -0.109271, 0.13588454, 0.10670471, 0.006712194, -0.24413653, 0.24706927, -0.20098938...\n",
       "3       [-0.20001145, 0.072584935, 0.52819365, -0.3378445, -0.061915454, 0.043990027, -0.064606726, 0.0736255, 0.19891483, 0.06754082, 0.20419908, -0.10599995, 0.13987637, 0.1068021, 0.28936264, -0.173550...\n",
       "4       [-0.0675545, 0.25669113, 0.31932634, -0.2808434, -0.2849553, 0.11903277, -0.22724922, 0.18872231, 0.06447208, -0.14311, 0.11120178, 0.12749399, 0.25818896, -0.103959456, 0.053848103, -0.3586756, 0...\n",
       "                                                                                                         ...                                                                                                   \n",
       "7915    [0.051952004, 0.2226675, 0.47940877, -0.34924498, 0.29066074, 0.48192868, -0.11545513, 0.22462589, -0.004092754, -0.15837748, 0.116602495, -0.045171246, -0.11651751, 0.071391806, 0.2810305, -0.102...\n",
       "7916    [-0.18098007, 0.12464717, 0.33349824, -0.22868147, -0.10065188, 0.11223518, 0.09280707, 0.19630194, -0.03820183, -0.103406295, 0.17366508, 0.02535759, 0.035441183, -0.157509, 0.22485223, -0.149603...\n",
       "7917    [-0.095649526, 0.19740604, 0.34863177, -0.13902606, -0.15983284, 0.16839392, -0.0051252632, 0.33274135, 0.10390416, 0.14928617, 0.15503775, 0.06990384, 0.28915715, 0.016010884, 0.22089238, -0.2586...\n",
       "7918    [-0.15797022, 0.06897492, 0.41461456, -0.25585368, 0.16043809, 0.06087252, 0.049134072, 0.00858561, 0.24010862, 0.031651918, 0.40196037, 0.009148378, 0.070672765, -0.05613039, 0.24265353, -0.09566...\n",
       "7919    [-0.033763997, -0.20432308, 0.20888498, -0.3193422, 0.3165843, 0.0934306, 0.19030476, 0.086376995, 0.15743901, -0.11902139, 0.34510654, -0.1679287, 0.26652008, -0.2961487, 0.09412909, 0.054135002,...\n",
       "Name: cleaned_tweets, Length: 7920, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_temp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c05605b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7920, 100)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combining all the document vectors into a singl numpy array (tweets_vec)\n",
    "embedding_size = 100\n",
    "tweets_vec1 = np.ones((len(tweets_temp1), embedding_size))*np.nan\n",
    "\n",
    "for i in range(tweets_vec1.shape[0]):\n",
    "    tweets_vec1[i,:] = tweets_temp1.iloc[i]\n",
    "\n",
    "# tweets_vec.shape # this itself is your final FEATURE MATRIX\n",
    "# Create a new DF to store these new documnent features\n",
    "df1 = pd.DataFrame(tweets_vec1)\n",
    "df1['y'] = tweets['label']\n",
    "df1.dropna(how='any', axis=0, inplace=True)\n",
    "\n",
    "X_word_emb_Glove = df1.drop('y', axis=1)\n",
    "y = df1['y']\n",
    "X_word_emb_Glove.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e07b7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4fe5ee7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8716 0.0015\n",
      "0.8672 0.0079\n"
     ]
    }
   ],
   "source": [
    "LR = LogisticRegression(solver='liblinear', class_weight='balanced', penalty='l2', C=0.5)\n",
    "\n",
    "results = cross_validate(LR, X_word_emb_Glove, y, scoring='accuracy', cv=kfold, \\\n",
    "                         return_train_score=True, return_estimator=True)\n",
    "print(results['train_score'].mean().round(4), results['train_score'].std().round(4))\n",
    "print(results['test_score'].mean().round(4), results['test_score'].std().round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d6ae77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# H/W Try re-building the model using 300d vectors from GoogleNews.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df90986",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405a0bbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda01ee4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
